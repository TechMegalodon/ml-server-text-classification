{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification for the Newsgroups20 data set with Python.\n",
    "\n",
    "When a customer sends a support ticket, it is important to route it to the right team in order to examine the issue and solve it in the fastest way possible. This notebook uses a preprocessed version of the NewsGroups20, containing a Subject, a Text, and a Label (20 classes). It has a similar structure to a support ticket data set which would also have two data fields: Title, and Problem description.\n",
    "\n",
    "This notebook takes advantage of the power of SQL Server and RevoScalePy. The tables are all stored in a SQL Server, and most of the computations are done by loading chunks of data in-memory instead of the whole dataset.\n",
    "\n",
    "It does the following: \n",
    "\n",
    " * **Step 0: Modules, Compute Contexts and Database Creation**\n",
    " * **Step 1: Loading the data to SQL Server**\n",
    " * **Step 2: Create features on the fly for the training set and train the model**\n",
    " * **Step 3: Create features on the fly for the testing set, make predictions, and evaluate the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Modules, Compute Contexts and Database Creation\n",
    "\n",
    "#### In this step, we set up the connection string to access a SQL Server Database we create and load the necessary packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT DATA SETS: point to the correct path.  \n",
    "News_Train = \"../Data/News_Train\"\n",
    "News_Test = \"../Data/News_Test\"\n",
    "Label_Names = \"../Data/Label_Names\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules. \n",
    "import os\n",
    "import pyodbc\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from revoscalepy import RxInSqlServer, RxLocalSeq, RxSqlServerData, RxOdbcData, RxTextData\n",
    "from revoscalepy import rx_set_compute_context, rx_data_step, rx_import, rx_write_object\n",
    "from microsoftml import rx_logistic_regression, featurize_text, n_gram_hash, rx_predict\n",
    "from microsoftml.entrypoints._stopwordsremover_predefined import predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the connection string. Specify:\n",
    "## Database name. If it already exists, tables will be overwritten. If not, it will be created.\n",
    "## Server name. If conecting remotely to the DSVM, the full DNS address should be used with the port number 1433 (which should be enabled) \n",
    "## User ID and Password. Change them below if you modified the default values.  \n",
    "server_name = \"localhost\"\n",
    "db_name = \"TextClassification_Py\"\n",
    "\n",
    "connection_string = 'DRIVER={};SERVER={};DATABASE={};TRUSTED_CONNECTION=Yes'.format(\"SQL Server\", server_name, db_name)\n",
    "\n",
    "# Define SQL and Local Compute Contexts.\n",
    "sql = RxInSqlServer(connection_string = connection_string, num_tasks = 1)\n",
    "local = RxLocalSeq()\n",
    "\n",
    "print(\"Connection String Written.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database if it does not already exist.\n",
    "\n",
    "## Open a pyodbc connection to the master database to create db_name. \n",
    "connection_string_master = 'DRIVER={};SERVER={};DATABASE=master;TRUSTED_CONNECTION=Yes'.format(\"SQL Server\", server_name)\n",
    "cnxn_master = pyodbc.connect(connection_string_master, autocommit = True)\n",
    "cursor_master = cnxn_master.cursor()\n",
    "query_db = \"if not exists(SELECT * FROM sys.databases WHERE name = '{}') CREATE DATABASE {}\".format(db_name, db_name)\n",
    "cursor_master.execute(query_db)\n",
    "\n",
    "## Close the pyodbc connection to the master database. \n",
    "cursor_master.close()\n",
    "del cursor_master\n",
    "cnxn_master.close() \n",
    "\n",
    "print(\"Database created if not already existing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function below can be used to get the top n rows of a table stored on SQL Server. \n",
    "#### You can execute this cell throughout your progress by removing the comment \"#\", and inputting:\n",
    "#### - the table name.\n",
    "#### - the number of rows you want to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_head(table_name, n_rows):\n",
    "    Table_sql = RxSqlServerData(sql_query = \"SELECT TOP({}) * FROM {}\".format(n_rows, table_name), connection_string = connection_string)\n",
    "    Table_df = rx_import(Table_sql)\n",
    "    print(Table_df)\n",
    "\n",
    "# table_name = \"News_Train\"\n",
    "# n_rows = 10\n",
    "# display_head(table_name, n_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data to SQL Server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the compute context to Local. \n",
    "rx_set_compute_context(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Point to the txt data sets.\n",
    "News_Train_text = RxTextData(file = News_Train, delimiter = \"\\t\")\n",
    "News_Test_text = RxTextData(file = News_Test, delimiter = \"\\t\")\n",
    "Label_Names_text = RxTextData(file = Label_Names, delimiter = \"\\t\")\n",
    "\n",
    "# Point to the SQL tables where they will be written. \n",
    "News_Train_sql = RxSqlServerData(table = \"News_Train\", connection_string = connection_string)\n",
    "News_Test_sql = RxSqlServerData(table = \"News_Test\", connection_string = connection_string)\n",
    "Label_Names_sql = RxSqlServerData(table = \"Label_Names\", connection_string = connection_string)\n",
    "\n",
    "# Export them to SQL Server.\n",
    "rx_data_step(input_data = News_Train_text, output_file = News_Train_sql, overwrite = True)\n",
    "rx_data_step(input_data = News_Test_text, output_file = News_Test_sql, overwrite = True)\n",
    "rx_data_step(input_data = Label_Names_text, output_file = Label_Names_sql, overwrite = True)\n",
    "\n",
    "print(\"Data exported to SQL Server.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create features on the fly for the training set and train the model.\n",
    "\n",
    "In this step, we:\n",
    "\n",
    "**1.** Get the factor levels of the label.\n",
    "\n",
    "**2.** Define the transformation to be used to generate text features. \n",
    "\n",
    "**3.**  Train a multiclass Logistic Regression Model while featurizing the text variables separately on the fly. \n",
    "\n",
    "**Input:** Training set News_Train.\n",
    "\n",
    "**Output:** Multiclass Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the factor levels of the label.\n",
    "Factors_sql = RxSqlServerData(sql_query = \"SELECT DISTINCT Label FROM News_Train\",\n",
    "                              connection_string = connection_string)\n",
    "levels_list  = list(rx_import(Factors_sql)['Label'])\n",
    "\n",
    "# Write the factor name and levels into a dictionary.\n",
    "factor_info = {'Label':{'type' : 'factor', 'levels' : [str(s) for s in levels_list]}}\n",
    "\n",
    "print(\"Label levels retreived.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the formula for training. \n",
    "## The Subject and Text are featurized separately in order to give to the words in the Subject the same weight as those in the Text. \n",
    "training_formula = \"Label ~ SubjectPreprocessed + TextPreprocessed\"\n",
    "\n",
    "print(\"Formula written.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation to be used to generate features. \n",
    "# It will be applied on the fly during training and testing.\n",
    "## Here, for each of the Subject and the Text separately, we: \n",
    "## - Remove stopwords, diacritics, punctuation and numbers.\n",
    "## - Change capital letters to lower case. \n",
    "## - Hash the different words and characters. \n",
    "## The parameters or options can be further optimized by parameter sweeping.\n",
    "## Other languages can be used.\n",
    "text_transform_list =[featurize_text(cols = dict(SubjectPreprocessed = \"Subject\", TextPreprocessed = \"Text\"), \n",
    "                                     language = \"English\",\n",
    "                                     stopwords_remover = predefined(),\n",
    "                                     case = \"Lower\",\n",
    "                                     keep_diacritics  = False,                                                   \n",
    "                                     keep_punctuations = False,\n",
    "                                     keep_numbers = False,\n",
    "                                     word_feature_extractor = n_gram_hash(hash_bits = 17, ngram_length = 2, seed = 4),\n",
    "                                     char_feature_extractor = n_gram_hash(hash_bits = 17, ngram_length = 3, seed = 4),\n",
    "                                     vector_normalizer = \"L2\")]\n",
    "  \n",
    "print(\"Text transfomation defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the compute context to SQL for training. \n",
    "rx_set_compute_context(sql) \n",
    "\n",
    "# Point to the training set. \n",
    "News_Train_sql = RxSqlServerData(table = \"News_Train\",\n",
    "                                 connection_string = connection_string,\n",
    "                                 column_info = factor_info)\n",
    "\n",
    "# Train the multiclass Logistic Regression Model.\n",
    "logistic_model = rx_logistic_regression(formula = training_formula,\n",
    "                                        data = News_Train_sql,\n",
    "                                        method = \"multiClass\",\n",
    "                                        l2_weight = 1, \n",
    "                                        l1_weight = 1,\n",
    "                                        ml_transforms = text_transform_list,\n",
    "                                        train_threads = 4)\n",
    "\n",
    "print(\"Multiclass Logistic Regression trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and save the model to SQL Server. \n",
    "rx_set_compute_context(local)\n",
    "models_odbc = RxOdbcData(connection_string, table = \"Model\")\n",
    "rx_write_object(models_odbc, key = \"LR\", value = logistic_model, serialize = True, overwrite = True)\n",
    "\n",
    "# Set the Compute Context back to SQL.\n",
    "rx_set_compute_context(sql)\n",
    "\n",
    "print(\"Model saved to SQL Server.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create features on the fly for the testing set, make predictions, and evaluate the model.\n",
    "\n",
    "In this step, we:\n",
    "\n",
    "**1.** Score the logistic regression on the testing set, while featurizing the two text variables. \n",
    "\n",
    "**2.** Evaluate the model. \n",
    "\n",
    "**Input:** Testing set News_Test and Multiclass Logistic Regression model.\n",
    "\n",
    "**Output:** Predictions and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Scoring\n",
    "\n",
    "## Point to the testing set. \n",
    "News_Test_sql = RxSqlServerData(table = \"News_Test\",\n",
    "                                connection_string = connection_string,\n",
    "                                column_info = factor_info)\n",
    "\n",
    "# Make Predictions while featurizing the text variables separately on the fly.\n",
    "# This will automatically use the same text transformation as in the training, encoded in logistic_model.\n",
    "Predictions_Intermediate_sql = RxSqlServerData(table = \"Predictions_Intermediate\", connection_string = connection_string)\n",
    "\n",
    "rx_predict(model = logistic_model,\n",
    "           data = News_Test_sql,\n",
    "           output_data = Predictions_Intermediate_sql,\n",
    "           extra_vars_to_write = [\"Label\", \"Id\"],\n",
    "           overwrite = True)\n",
    "\n",
    "# Get the real label names.\n",
    "Join_Query_sql = RxSqlServerData(sql_query = \"SELECT LabelNames, Predictions_Intermediate.* \\\n",
    "                                              FROM Predictions_Intermediate INNER JOIN Label_Names \\\n",
    "                                              ON Predictions_Intermediate.PredictedLabel = Label_Names.Label\", \n",
    "                                connection_string = connection_string)\n",
    "\n",
    "Predictions_sql = RxSqlServerData(table = \"Predictions\", connection_string = connection_string, strings_as_factors = True)\n",
    "rx_data_step(input_data = Join_Query_sql, output_file = Predictions_sql, overwrite = True)\n",
    "\n",
    "print(\"Scoring done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model. \n",
    "Predictions_df = rx_import(Predictions_sql)\n",
    "Conf_Matrix = confusion_matrix(y_true = Predictions_df[\"Label\"], y_pred = Predictions_df[\"PredictedLabel\"])\n",
    "\n",
    "# Compute Evaluation Metrics. \n",
    "## Micro Average accuracy: \n",
    "micro = sum(Conf_Matrix[i][i] for i in range(Conf_Matrix.shape[0]))/Predictions_df.shape[0]\n",
    "print(\"Micro Average Accuracy is {}\".format(micro))\n",
    "\n",
    "## Macro Average accuracy:\n",
    "macro = sum(Conf_Matrix[i][i]/(sum(Conf_Matrix[i][j] for j in range(Conf_Matrix.shape[0]))) for i in range(Conf_Matrix.shape[0]))/Conf_Matrix.shape[0]\n",
    "print(\"Macro Average Accuracy is {}\".format(macro))\n",
    "\n",
    "## Per-class precision, recall and F1-score. \n",
    "results = classification_report(y_true = Predictions_df[\"Label\"], y_pred = Predictions_df[\"PredictedLabel\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at a subset of the predictions. \n",
    "display_head(table_name = \"Predictions\", n_rows = 10)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "ML Server Python",
   "language": "python",
   "name": "mlserver-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
